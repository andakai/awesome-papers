{"./":{"url":"./","title":"Introduction","keywords":"","body":"Introduction paper lists and my thoughts Copyright © 版权信息 all right reserved，powered by Gitbook该文件修订时间： 2024-05-16 20:02:07 "},"Lists/MLSYS/":{"url":"Lists/MLSYS/","title":"MLSYS","keywords":"","body":"MLSYS LLM Agent Copyright © 版权信息 all right reserved，powered by Gitbook该文件修订时间： 2024-05-17 11:21:58 "},"Lists/MLSYS/LLM/":{"url":"Lists/MLSYS/LLM/","title":"LLM","keywords":"","body":"LLM LLM Training LLM Inference Copyright © 版权信息 all right reserved，powered by Gitbook该文件修订时间： 2024-05-16 20:41:10 "},"Lists/MLSYS/Agent/":{"url":"Lists/MLSYS/Agent/","title":"Agent","keywords":"","body":"Agent Survey [arXiv24] ✅ The-Landscape-of-Emerging-AI-Agent-Architectures-for-Reasoning-Planning-and-Tool-Calling-A-Survey paper note [arXiv24] From Persona to Personalization: A Survey on Role-Playing Language Agents paper [arXiv24] ✅ A Survey on Large Language Model based Autonomous Agents paper code note [Others] Language Agents From Next-Token Prediction to Digital Automation paper video Benchmark [NIPS22] ✅ WebShop: Towards Scalable Real-World Web Interaction with Grounded Language Agents paper note [NIPS23] ✅ InterCode: Standardizing and Benchmarking Interactive Coding with Execution Feedback paper code note [ICLR24] AgentBench: Evaluating LLMs as Agents paper code Planning [NIPS22] Chain-of-Thought Prompting Elicits Reasoning in Large Language Models paper note [arXiv23] Tree of Thoughts: Deliberate Problem Solving with Large Language Models paper [ICLR23] ReAct: Synergizing Reasoning and Acting in Language Models paper code [NIPS23] Reflexion: Language Agents with Verbal Reinforcement Learning paper code [arXiv23] Chain of Hindsight Aligns Language Models with Feedback paper [arXiv24] AutoGPT+P: Affordance-based Task Planning with Large Language Models. paper [ICML24] Language Agent Tree Search Unifies Reasoning Acting and Planning in Language Models. paper code Memory [arXiv24] From LLM to Conversational Agent: A Memory Enhanced Architecture with Fine-Tuning of Large Language Models paper Tool Use [ICLR24] ToolLLM: Facilitating Large Language Models to Master 16000+ Real-world APIs paper code Collaboration [arXiv24] Embodied LLM Agents Learn to Cooperate in Organized Teams. paper code [arXiv23] Dynamic LLM-Agent Network: An LLM-agent Collaboration Framework with Agent Team Optimization. paper code [ICLR24] AgentVerse: Facilitating Multi-Agent Collaboration and Exploring Emergent Behaviors. paper code [ICLR24] MetaGPT: Meta Programming for A Multi-Agent Collaborative Framework. paper code Repositories Paper List hyp1231/awesome-llm-powered-agent ysymyth/awesome-language-agents thunlp/ToolLearningPapers (github.com) AGI-Edgerunners/LLM-Agents-Papers: A repo lists papers related to LLM based agent (github.com) LLM Powered Autonomous Agents | Lil'Log (lilianweng.github.io) Agent System Projects AutoGPT XAgent AgentGPT BabyAGI Blog ✅ The Shift from Models to Compound AI Systems Blog note ✅ 四万字长文：AI Agent 应该更有趣还是更有用？Blog 大语言模型智能体简介 Copyright © 版权信息 all right reserved，powered by Gitbook该文件修订时间： 2024-05-21 01:31:15 "},"Notes/Conference/":{"url":"Notes/Conference/","title":"Conference","keywords":"","body":"Conference 2024 ASPLOS 24 2023 ASPLOS 23 Copyright © 版权信息 all right reserved，powered by Gitbook该文件修订时间： 2024-05-16 20:45:39 "},"Notes/Conference/ASPLOS24/":{"url":"Notes/Conference/ASPLOS24/","title":"ASPLOS24","keywords":"","body":"ASPLOS24 Papers Copyright © 版权信息 all right reserved，powered by Gitbook该文件修订时间： 2024-05-16 20:46:13 "},"Notes/Conference/NIPS23/":{"url":"Notes/Conference/NIPS23/","title":"NIPS23","keywords":"","body":"NIPS23 Copyright © 版权信息 all right reserved，powered by Gitbook该文件修订时间： 2024-05-19 15:27:35 "},"Notes/Conference/NIPS23/InterCode-Standardizing-and-Benchmarking-Interactive-Coding-with-Execution-Feedback.html":{"url":"Notes/Conference/NIPS23/InterCode-Standardizing-and-Benchmarking-Interactive-Coding-with-Execution-Feedback.html","title":"InterCode-Standardizing-and-Benchmarking-Interactive-Coding-with-Execution-Feedback","keywords":"","body":"InterCode: Standardizing and Benchmarking Interactive Coding with Execution Feedback 2024-05-19 Summary Because of the drawback of static coding benchmarks, this paper proposes an interactive benchmark InterCode, which can benefit from the interactive code understanding and generation. Applied to interpreted languages, like bash, sql, python. Motivation drawback of static, sequence-to-sequence or auto-regressive fashion: no chance to recovery or revision disconnection between generation and execution little room for human intervention Method construction environment prepared: docker dataset: (query, gold) (gold is the right execution result) reward design two metrics: success rate and error % interactive intercode-bash: dockerfile defines a bash environment NL2Bash -> filter out some commands and form 4 sets execution output: graded with a simple lexical similarity function file system change: check the operation list, md5sum hashes each file path to check correctness intercode-sql is the similar. intercode-python straightforwardly uses the MBPP dataset. prompting strategies: single turn try again: terminate until reward = 1 ReAct, Plan & Solve: termination determined by the agent Evaluation Strengths and Weaknesses Strengths: interactive code benchmark the reward function of the bash codes Weaknesses:** Further Ideas “it may be possible to make significant advancements in the interactive coding task with prompting strategies that attempt to elicit reasoning via an appropriate framework that also permits the model to be expressive and creative in devising its own solutions” (Yang 等, 2023, p. 23) compiled languages support extend to other areas (the paper has pointed out these two) Copyright © 版权信息 all right reserved，powered by Gitbook该文件修订时间： 2024-05-19 17:42:16 "},"Notes/Conference/NIPS22/":{"url":"Notes/Conference/NIPS22/","title":"NIPS22","keywords":"","body":"NIPS22 Copyright © 版权信息 all right reserved，powered by Gitbook该文件修订时间： 2024-05-19 00:57:31 "},"Notes/Conference/NIPS22/WebShop-Towards-Scalable-Real-World-Web-Interaction-with-Grounded-Language-Agents.html":{"url":"Notes/Conference/NIPS22/WebShop-Towards-Scalable-Real-World-Web-Interaction-with-Grounded-Language-Agents.html","title":"WebShop-Towards-Scalable-Real-World-Web-Interaction-with-Grounded-Language-Agents","keywords":"","body":"WebShop: Towards Scalable Real-World Web Interaction with Grounded Language Agents 2024-05-18 Summary This paper tries to solve the problems of existing benchmarks: bad scalability and lacking interaction with real-world. It sets web as the benchmark environment which satisfies scalability and interactivity. It builds a benchmark with 1.18m real-world products and 12087 text gernerations. It trains and evaluates using imitation learning(imitates humans's search and choosing operations) and online RL methods. Furthermore, it analyses the gap between humans and agents. Motivation Existing benchmark is not scalable and lack interaction. To build a good LLM, there is a need to find a scalable interactive environment: “(1) language elements that reflect rich, real-world usage and are collectible at scale, and (2) task feedback that is well-defined and automatically computable to facilitate interactive learning, without the constant need for expensive feedback from humans.” (Yao 等, 2023, p. 1) Web satisfies these needs. To further explore the benefit of this environment, this paper focuses on e-commerce. Abstraction of a task: state: web pages action: search sth choose a button state observation: HTML mode simple mode instruction U generated based on a target product by human annotators Uatt,Uopt,upriceU_{att}, U_{opt}, u_{price}U​att​​,U​opt​​,u​price​​ The first two are similar, descring the attributes of a a prompt. Reward Y is the chosen product. Method Imitation Learning Imitating human search generation: generate action based given an instruction Imitating human choice: train a model to maximize the likelihood of human's choice a* given the observation o. BERT encodes the observation o and each action into vectors. train the model to get the score(o,a) we use the BART model in the search page to generate the top-5 search queries via beam search and choose a random one. For other pages, we sample one action from πθ (a | o, A(o)) using the BERT model. Reinforcement Learning using online RL (not very clear about this part) Evaluation Strengths and Weaknesses Strengths: Build a scalable, realistic, web-based benchmark used for agents The task abstract is nice. (State, Action, Trasition(SxA->S), Reward, Instruction, Observation). The buying steps have something like CoT, but they are decomposed by humans. Analyze the gap between humans and agents and point the future direction Weakness: Focus on a specified topic e-commerce. Not extend to other areas. Still need finetuning the model. In other words, focus on internal state changing. Further Ideas We perform several analyses and ablation studies to identify the cause of this gap and find several avenues for agent improvement in the future, including more robust search generation, explicit memory modules, and better handling of noisy web text. Using external tools Memory module: memory module is important now. The buying steps are decomposed by humans. -> by LLMs Copyright © 版权信息 all right reserved，powered by Gitbook该文件修订时间： 2024-05-19 00:56:25 "},"Notes/Conference/NIPS22/Chain-of-Thought-Prompting-Elicits-Reasoning-in-Large-Language-Models.html":{"url":"Notes/Conference/NIPS22/Chain-of-Thought-Prompting-Elicits-Reasoning-in-Large-Language-Models.html","title":"Chain-of-Thought-Prompting-Elicits-Reasoning-in-Large-Language-Models","keywords":"","body":"Chain-of-Thought Prompting Elicits Reasoning in Large Language Models 2024-05-20 Summary It tries to mimic a step-by-step thought process for arriving at the answer as humans. So it manually composed a set of few-shot exemplars with chains of thought for prompting. This can guide the LLM to do chain-of-thought, which largely improves the performance in various datasets. This phenomenon only emerge as the LLM model becomes as large as hundreds of Bs and for those problems which need complicated reasoning. Evaluation This paper does experiments on arithmetic reasoning, commonsense reasoning, symbolic reasoning. Let's emphasize on its ablation study of arithmetic. This part analyses probably why CoT works. Equation only: To test whether the math equation helps. setup: the output is only a mathematical equation before the answer no effect when the question is complicated Variable compute only: To test whether the computation helps. setup: the output is replaced with ... equal to the total length no effect Chain of thought after answer: To test the CoT is not reasoning, but can better access relevant knowledge. setup: put the CoT prompts after the answer (So that when giving the answer, the LLM doesn't rely on the CoT, but CoT process is still inserted into the LLM. The similar idea is adding \"think step by step in the end\") no effect. The robustness is concluded by different anatators writing the CoT prompts. OOD evaluation reveals the CoT can facilitate length generalization. Strengths and Weaknesses Strengths: Good prompt engineering I think the evaluation and the analysis are nice. It discusses the inner reasons about CoT. Weaknesses: This paper doesn't answer whether the neural network is reasoning Manually doing CoT exemplars is prohibitive for finetuning No guarantee of correct reasoning path Only emerge in large models (The above is given in the paper already)Further Ideas I didn't know such prompt method before. I think it is very inspiring, making people to think about Is the LLM really reasoning? I am still curious about the third ablation study-Chain of thought after answer. If there exists a completely perfect LLM, give it a prompt, no matter there is a CoT exemplar or not, this LLM will give the right answer. oh we can compare the best LLM to the best optimizer, and other worse optimizers may arrive at a local-best but not a global-best point. Maybe CoT gives a good start to optimize to the best point or a better optimizer. (not accurate analogy). All in all, what I want to express is that, if we have a perfect LLM, there may be no need to do prompt engineering, the LLM itself can reach the right answer. But as the imperfect LLMs can reach the right answer, so the reasoning path itself may already be in the LLM, but CoT makes it clear. (random thoughts) Copyright © 版权信息 all right reserved，powered by Gitbook该文件修订时间： 2024-05-21 01:29:48 "},"Notes/Journal/":{"url":"Notes/Journal/","title":"Journal","keywords":"","body":"Journal Copyright © 版权信息 all right reserved，powered by Gitbook该文件修订时间： 2024-05-16 20:24:20 "},"Notes/Arxiv/":{"url":"Notes/Arxiv/","title":"Arxiv","keywords":"","body":"Arxiv Copyright © 版权信息 all right reserved，powered by Gitbook该文件修订时间： 2024-05-17 12:06:04 "},"Notes/Arxiv/2024/":{"url":"Notes/Arxiv/2024/","title":"2024","keywords":"","body":"2024 Copyright © 版权信息 all right reserved，powered by Gitbook该文件修订时间： 2024-05-17 11:17:15 "},"Notes/Arxiv/2024/The-Landscape-of-Emerging-AI-Agent-Architectures-for-Reasoning-Planning-and-Tool-Calling-A-Survey.html":{"url":"Notes/Arxiv/2024/The-Landscape-of-Emerging-AI-Agent-Architectures-for-Reasoning-Planning-and-Tool-Calling-A-Survey.html","title":"The-Landscape-of-Emerging-AI-Agent-Architectures-for-Reasoning-Planning-and-Tool-Calling-A-Survey","keywords":"","body":"The Landscape of Emerging AI Agent Architectures for Reasoning, Planning, and Tool Calling: A Survey 2024-05-16 Basic Concept Agent：由大模型驱动的，可以在多轮迭代中执行任务的实体。 Agent Persona：Agent的角色或性格，还包括agent能够使用的工具的描述 Tools：Agent能够调用的任何函数。可以和外界的数据进行交互 Single Agent Architecture：单个Agent的系统 Multi-Agent Architectures：多Agent系统 Key Consideration for Agent Reasoning 在Plan or act之前，需要经过Reasoning，否则只能基于对请求的简单理解，或存在对请求的误解。 Planning 在有强大推理能力的基础上进行。 task decomposition multi-plan selection：从多个生成的选项中选择一个 external module-aided planning：利用外部已经存在的计划 reflection and refinement：根据新的信息进行反思，修订之前的计划 memory-augmented planning：利用额外的数据、信息 Tool calling 区别于普通的prompt-base的模型的点，即可以call tools 外部的数据源、利用已有的API Single Agent “We find that single agent architectures are especially useful when the task requires straightforward function calling and does not need feedback from another agent” ReAct： Reason + Act 对给定的任务做Reason，得到一个想法，再根据这个想法Act RAISE： ReAct + 记忆机制 引入长短记忆数据库。在长对话中能保持能力 缺点：没有强大的逻辑，角色容易混乱 Reflexion： sefl-reflection 利用LLM evaluator来实时为agent做出反馈 减少了幻觉的产生 AutoGPT+ P： object detection + Object Affordance Mapping 在一个场景下检测现在的对象，LLM根据对象判断使用的Tool：Plan, Partial Plan, Suggest Alternative, Explore。 LLM本身不生产Plan，而只生成目标，让classical planner生成Plan。原因：认为LLM的推理能力不足。 缺点：工具选择不准确导致卡住；exploration阶段不合理的工具选择；执行时无法与人交互 LATS： Language Agent Tree Search 引入self-reflection手段：在执行了一个操作后，根据反馈判断是否在推理时出现问题，并尝试提出新方法。 缺点：算法复杂性高 Multi Agent “Multi-agent architectures create an opportunity for both the intelligent division of labor based on skill and helpfu feedback from a variety of agent personas.” clear leadership dynamic team construction effective information sharing between team members Embodied LLM Agents Learn to Cooperate in Organized Teams： multi-agent中有一个organized leader时效果比没有leader好 criticize-reflect：生成计划、评判效果、给出反馈、进行组织调整(dynamic team structure) DyLAN： 判断每个Agent在上一轮中的贡献，在下一轮中只使用最高贡献的几个Agent dynamic team的应用 AgentVerse： recruiment：动态地添加、移除Agent collaborative decision making independent action execution evaluation 发现了：horizontal结构适合collaborative tasks，而vertical结构适合在call tools时独立性好的任务。 MetaGPT： 通过让agent生成结构化的输出，比如文件、图表，而不是分享非结构化的语言，解决了agents之间的没有用的对话的问题 发布-订阅者模式：解决信息分享的问题。避免了agents之间不必要的交流 Findings Agent的工作流：plan -> act -> evaluate 通用的优化方式： 清晰的反馈 任务分解 迭代改进 定义角色 Single vs Multi 应用场景 执行任务时的效率 反馈的重要性 Multi时的组织层次：horizontal vs vertical 角色定义和动态的组织调整 Limitations of Current research agent evaluation 好的benchmark的重要性 现实应用的benchmark Agent system中的偏见与危害 Copyright © 版权信息 all right reserved，powered by Gitbook该文件修订时间： 2024-05-17 14:31:02 "},"Notes/Arxiv/2024/A-Survey-on-Large-Language-Model-based-Autonomous-Agents.html":{"url":"Notes/Arxiv/2024/A-Survey-on-Large-Language-Model-based-Autonomous-Agents.html","title":"A-Survey-on-Large-Language-Model-based-Autonomous-Agents","keywords":"","body":"2024-05-17 A Survey on Large Language Model based Autonomous Agents Metadata Lei Wang1, Chen Ma1, Xueyang Feng1, Zeyu Zhang1, Hao Yang1, Jingsen Zhang1, Zhi-Yuan Chen1, Jiakai Tang1, Xu Chen(B)1, Yankai Lin(B)1, Wayne Xin Zhao1, Zhewei Wei1, Ji-Rong Wen1 1 Gaoling School of Artificial Intelligence, Renmin University of China, Beijing, 100872, China Summary construction of agents, their applications, and methods of evaluation Introduction traditional agents simple and heuristic policy functions isolated and restricted enviroments LLM-based agents comprehensive internal world knowledge natural interfaces with humans “key idea is to equip LLMs with crucial human capabilities like memory and planning to make them behave like humans and complete various tasks effectively.” Construction Effectively leverage LLMs: which architecture should be designed to better use LLMs give the designed architecture, how to enable the agent to acquire capabilities for accomplishing specific tasks Interesting Analogy designing the agent architecture determining the network structure agent capability acquisition learning the network parameters Design To bridge the gap between traditional LLMs and autonomous agents, a crucial aspect is to design rational agent architectures to assist LLMs in maximizing their capabilities The purpose of the profiling module is to The memory and planning modules place the agent into a dynamic environment, enabling it to recall past behaviors and plan future actions. The action module is responsible for translating the agent’s decisions into specific outputs. Profiling Module: identify the role of the agent. handcrafting method: mannual agent profiles flexible labor-intensive LLM-generation Method: LLM generate save labor lack precise control Dataset Alignment Method: obtained from real-world datasets Memory Module: stores information perceived from the environment and leverages the recorded memories to facilitate future actions Structures: short/long-term memory Unified Memory: in-context learning, short-term memory memory information is written in prompts hard to put all memories into prompt Hybrid Memory: prompt(short) and external database(long) Formats: natural language memory: agent behaviors and observations are directly described using raw natural language flexible and understandable rich semantic information embedding memory: memory information is encoded into embedding vectors enhance memory retrieval and reading efficiency databases: memory information is stored in databases utilize SQL memory module is based on a database Structured Lists: memory information is organized into lists the semantic of memory can be conveyed efficient and concise Memory Operations: interaction with enviroments memory reading: extract meaningful information from memory recency, relevance, importance m∗=argminm∈Mαsrec(q,m)+βsrel(q,m)+γsimp(m)m^{*}=\\arg \\min _{m \\in M} \\alpha s^{r e c}(q, m)+\\beta s^{r e l}(q, m)+\\gamma s^{i m p}(m)m​∗​​=argmin​m∈M​​αs​rec​​(q,m)+βs​rel​​(q,m)+γs​imp​​(m), choose m* as the memory to extract. memory writing: store information about the perceived environment memory duplicated using LLM to condense the similar sequences aggregate via count accumulation memory overflow: user delete FIFO memory reflection: summarize into broader and more abstract insights (Generative agents) generate questions based on memory -> query memory to obtain relevavnt infomation -> generate five insights low-level -> high-level The memory module can help the agent to accumulate experiences, self-evolve, and behave in a more consistent, reasonable, and effective manner. “Human memory follows a general progression from sensory memory that registers perceptual inputs, to short-term memory that maintains information transiently, to longterm memory that consolidates information over extended periods.” “integrating both short-term and longterm memories can enhance an agent’s ability for long-range reasoning and accumulation of valuable experiences, which are crucial for accomplishing tasks in complex environments” “The memory module plays a critical role in allowing the agent to acquire, accumulate, and utilize significant knowledge by interacting with the environment” Planning Module: deconstruct into simpler subtasks and solve them independently without feedback Single-path Reasoning: each step leading to only one subsequent step Chain of Thought: proposes inputting reasoning steps for solving complex problems into the prompt Multi-path Reasoning: the reasoning steps organized into a tree-like structure using a tree-like reasoning structure COT-SC, ToT external planners: generate plans for domain-specific problems with feedback environment thought-act-observation (ReAct) intermediate progress of execution, execution error, self-verification (Voyager) environment states and executed action information human make the agent align with the human values and preferences alleviate the hallucination problem model output-feedback-refinement “CO-LLM demonstrates that LLMs is good at generating high-level plans, but struggle with low-level control. To address this limitation, a heuristically designed external low-level planner is employed to effectively execute actions based on high-level plans. Action Module: interacts with the environment Action goal Task completion: to complete specific task Communication: to communicate with agents or humans Environment exploration: to explore unfamiliar environments to expand its perception Action production Action via Memory Recollection: generated by memory and task Action via Plan Following: pre-generated plans generate action plans first decomposing the task into sub-goals and make plans. Action space: the set of possible actions external tools: call external tools for executing action APIs: existing APIs, API invoked by LLM Databases & knowledge Bases External Models: incorporates other models inernal knowledge of LLMs capabilities of LLMs: plan, conversation, understanding Action impact Change environment Alter internal states Agent Capability Acquisition The architecture functions as the “hardware” of the agent. The agent may lack the necessary task-specific capabilities, skills and experiences, which can be regarded as \"software\" resources. Capability Acquisition with Fine-tuning Human Annotated Datasets: align with humans, costly LLM Generated Datasets: cheap Real-world Datasets Capability Acquisition without Fine-tuning Prompt engineering CoT-like agent beliefs about mental states inject reflections Mechanism Engineering Trial-and-error: action-judge-error-incorporate feedbacks Crowd-sourcing: multi agents learn from each other's idea to reach consensus Experience Accumulation: extract past memory to solve similar task Self-driven Evolution In the era of agents, the model capability can be acquired based on three strategies:(1) model fine-tuning, (2) prompt engineer and (3) designing proper agent evolution mechanisms Application social science psychology: different profiles political science and economy: predict voting, political speech, economic behavior social simulation jurisprudence research assistant natural science documentation and data management experiment assistant education engineering civil engineering: design cs & se: code industrial automation: control of procedure robotics & embodied: plan, reason, collaborate libraries to easily implement/evaluate: LangChain: automates coding, testing, debugging and documentation XLang, AutoGPT... Evaluation subjective evaluation human annotation: human score or rank Turing Test: separate the outputs by humans and agents use of LLMs objective evaluation metrics Task success metrics Human similarity metrics Efficiency metrics length of planning cost associated with devolopment speed of inference number of clarification dialogue Protocols: how to leverage these metrics to evaluate the capability Real-world simulation: in real environments Social evaluation: assess social intelligence based on agent interaction Multi-task evaluation: generalization capability Software testing Benchmarks Challenges role-playing capability fine-tuning design tailored agent prompts/architecture “In addition, previous research [30] has shown that existing LLMs may not well model the human cognitive psychology characters, leading to the lack of self-awareness in conversation scenarios” (Wang 等, 2024, p. 32) Generalized Human Alignment when the agents are leveraged for real-world simulation, an ideal simulator should be able to honestly depict diverse human traits, including the ones with incorrect values. Prompt Robustness agents, as they encompass not a single prompt but a prompt framework that considers all modules, wherein the prompt for one module has the potential to influence others. Hallucination incorporating human correction feedback Knowledge Boundary how to simulate diverse real-world human behaviors? constrain the utilization of user-unknown knowledge of LLM LLMs may make decisions based on their extensive knowledge, even though real-world users would not have access to the contents Efficiency inference extract memory make plans before taking actions ... Copyright © 版权信息 all right reserved，powered by Gitbook该文件修订时间： 2024-05-18 15:03:41 "},"Notes/Blog/":{"url":"Notes/Blog/","title":"Blog","keywords":"","body":"Blog Copyright © 版权信息 all right reserved，powered by Gitbook该文件修订时间： 2024-05-16 20:43:22 "},"Notes/Blog/2024/":{"url":"Notes/Blog/2024/","title":"2024","keywords":"","body":"2024 Copyright © 版权信息 all right reserved，powered by Gitbook该文件修订时间： 2024-05-18 14:53:44 "},"Notes/Blog/2024/The-Shift-from-Models-to-Compound-AI-Systems.html":{"url":"Notes/Blog/2024/The-Shift-from-Models-to-Compound-AI-Systems.html","title":"The-Shift-from-Models-to-Compound-AI-Systems","keywords":"","body":"The Shift from Models to Compound AI Systems Metadata BAIR 20240218 Introduction state-of-the-art AI results are increasingly obtained by compound systems with multiple components, not just monolithic models. In enterprises, our colleagues at Databricks found that 60% of LLM applications use some form of retrieval-augmented generation (RAG), and 30% use multi-step chains. it means leading AI results can be achieved through clever engineering, not just scaling up training. 为什么使用Compound AI Systems？ We define a Compound AI System as a system that tackles AI tasks using multiple interacting components, including multiple calls to models, retrievers, or external tools. 尽管scaling law很有用，但是scaling的性价比不如一个compound system 模型是静态的，而一个系统可以是动态的，融入即时的数据 一个system更容易控制他的输出，以及通过RAG这样的方式可以让他的输出更具有可信度 AI模型只有一个固定的输出质量。但在不同场景，对于模型的输出质量要求不同。 挑战 Optimization 模型的优化一般就端到端训练，使用梯度下降更新参数，进行优化。而Compound AI system是由多个模块组成的，需要新的优化方式 DSPy优化了预训练模型和其他组成部分的流水线工作，而其他的LaMDA, Toolformer, AlphaGeometry是在模型训练的时候进行tools-specified的优化 Operation： Monitoring: How can developers most efficiently log, analyze, and debug traces from complex AI systems? DataOps: Because many AI systems involve data serving components like vector DBs, and their behavior depends on the quality of data served, any focus on operations for these systems should additionally span data pipelines. Security: Research has shown that compound AI systems, such as an LLM chatbot with a content filter, can create unforeseen security risks compared to individual models. New tools will be required to secure these systems. Paradigms 设计AI systems： Component libraries：langchain, llamaindex agent frameworks：AutoGPT, BabyAGI tools for controling LM outputs：Guardrails, Outlines, LMQL, SGLang 新的推理方式：COT, self-consistency, WikiChat, RAG Automatically Optimizing Quality: DSPy is the first framework that aims to optimize a system composed of LLM calls and other tools to maximize a target metric. **Optimizing Cost: FrugalGPT and AI Gateways Operation: 在执行过程中，需要跟踪应用的steps 跟踪、可视化、评判输出：LangSmith, Phoenix Traces, Databricks Inference Tables 利用监控得到的反馈：DSPy Assertions 利用AI来进行质量监测：MT-Bench, FAVA, ARES Copyright © 版权信息 all right reserved，powered by Gitbook该文件修订时间： 2024-05-18 14:58:23 "}}