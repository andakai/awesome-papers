
<!DOCTYPE HTML>
<html lang="zh-hans" >
    <head>
        <meta charset="UTF-8">
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <title>A-Survey-on-Large-Language-Model-based-Autonomous-Agents · awesome-papers</title>
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <meta name="description" content="">
        <meta name="generator" content="GitBook 3.2.3">
        <meta name="author" content="Dakai">
        
        
    
    <link rel="stylesheet" href="../../../gitbook/style.css">

    
            
                
                <link rel="stylesheet" href="../../../gitbook/gitbook-plugin-highlight/website.css">
                
            
                
                <link rel="stylesheet" href="../../../gitbook/gitbook-plugin-search-pro/search.css">
                
            
                
                <link rel="stylesheet" href="../../../gitbook/gitbook-plugin-expandable-chapters-small/expandable-chapters-small.css">
                
            
                
                <link rel="stylesheet" href="../../../gitbook/gitbook-plugin-splitter/splitter.css">
                
            
                
                <link rel="stylesheet" href="../../../gitbook/gitbook-plugin-code/plugin.css">
                
            
                
                <link rel="stylesheet" href="../../../gitbook/gitbook-plugin-anchor-navigation-ex/style/plugin.css">
                
            
                
                <link rel="stylesheet" href="../../../gitbook/gitbook-plugin-tbfed-pagefooter/footer.css">
                
            
                
                <link rel="stylesheet" href="../../../gitbook/gitbook-plugin-anchors/plugin.css">
                
            
                
                <link rel="stylesheet" href="../../../gitbook/gitbook-plugin-disqus/plugin.css">
                
            
                
                <link rel="stylesheet" href="../../../gitbook/gitbook-plugin-katex/katex.min.css">
                
            
                
                <link rel="stylesheet" href="../../../gitbook/gitbook-plugin-fontsettings/website.css">
                
            
        

    

    
        
    
        
    
        
    
        
    
        
    
        
    

        
    
    
    <meta name="HandheldFriendly" content="true"/>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <link rel="apple-touch-icon-precomposed" sizes="152x152" href="../../../gitbook/images/apple-touch-icon-precomposed-152.png">
    <link rel="shortcut icon" href="../../../gitbook/images/favicon.ico" type="image/x-icon">

    
    <link rel="next" href="../../Blog/" />
    
    
    <link rel="prev" href="The-Landscape-of-Emerging-AI-Agent-Architectures-for-Reasoning-Planning-and-Tool-Calling-A-Survey.html" />
    

    </head>
    <body>
        
<div class="book">
    <div class="book-summary">
        
            
<div id="book-search-input" role="search">
    <input type="text" placeholder="输入并搜索" />
</div>

            
                <nav role="navigation">
                


<ul class="summary">
    
    
    
        
        <li>
            <a href="https://andakai.github.io/" target="_blank" class="custom-link">我的个人博客</a>
        </li>
    
    

    
    <li class="divider"></li>
    

    
        
        
    
        <li class="chapter " data-level="1.1" data-path="../../../">
            
                <a href="../../../">
            
                    
                    Introduction
            
                </a>
            

            
        </li>
    

    
        
        <li class="header">PAPER LIST</li>
        
        
    
        <li class="chapter " data-level="2.1" data-path="../../../Lists/MLSYS/">
            
                <a href="../../../Lists/MLSYS/">
            
                    
                    MLSYS
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="2.1.1" data-path="../../../Lists/MLSYS/LLM/">
            
                <a href="../../../Lists/MLSYS/LLM/">
            
                    
                    LLM
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.1.2" data-path="../../../Lists/MLSYS/Agent/">
            
                <a href="../../../Lists/MLSYS/Agent/">
            
                    
                    Agent
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    

    
        
        <li class="header">READING NOTES</li>
        
        
    
        <li class="chapter " data-level="3.1" data-path="../../Conference/">
            
                <a href="../../Conference/">
            
                    
                    Conference
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="3.1.1" data-path="../../Conference/ASPLOS24/">
            
                <a href="../../Conference/ASPLOS24/">
            
                    
                    ASPLOS24
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="3.1.2" data-path="../../Conference/NIPS23/">
            
                <a href="../../Conference/NIPS23/">
            
                    
                    NIPS23
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="3.1.2.1" data-path="../../Conference/NIPS23/InterCode-Standardizing-and-Benchmarking-Interactive-Coding-with-Execution-Feedback.html">
            
                <a href="../../Conference/NIPS23/InterCode-Standardizing-and-Benchmarking-Interactive-Coding-with-Execution-Feedback.html">
            
                    
                    InterCode-Standardizing-and-Benchmarking-Interactive-Coding-with-Execution-Feedback
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="3.1.3" data-path="../../Conference/NIPS22/">
            
                <a href="../../Conference/NIPS22/">
            
                    
                    NIPS22
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="3.1.3.1" data-path="../../Conference/NIPS22/WebShop-Towards-Scalable-Real-World-Web-Interaction-with-Grounded-Language-Agents.html">
            
                <a href="../../Conference/NIPS22/WebShop-Towards-Scalable-Real-World-Web-Interaction-with-Grounded-Language-Agents.html">
            
                    
                    WebShop-Towards-Scalable-Real-World-Web-Interaction-with-Grounded-Language-Agents
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="3.1.3.2" data-path="../../Conference/NIPS22/Chain-of-Thought-Prompting-Elicits-Reasoning-in-Large-Language-Models.html">
            
                <a href="../../Conference/NIPS22/Chain-of-Thought-Prompting-Elicits-Reasoning-in-Large-Language-Models.html">
            
                    
                    Chain-of-Thought-Prompting-Elicits-Reasoning-in-Large-Language-Models
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="3.2" data-path="../../Journal/">
            
                <a href="../../Journal/">
            
                    
                    Journal
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="3.3" data-path="../">
            
                <a href="../">
            
                    
                    Arxiv
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="3.3.1" data-path="./">
            
                <a href="./">
            
                    
                    2024
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="3.3.1.1" data-path="The-Landscape-of-Emerging-AI-Agent-Architectures-for-Reasoning-Planning-and-Tool-Calling-A-Survey.html">
            
                <a href="The-Landscape-of-Emerging-AI-Agent-Architectures-for-Reasoning-Planning-and-Tool-Calling-A-Survey.html">
            
                    
                    The-Landscape-of-Emerging-AI-Agent-Architectures-for-Reasoning-Planning-and-Tool-Calling-A-Survey
            
                </a>
            

            
        </li>
    
        <li class="chapter active" data-level="3.3.1.2" data-path="A-Survey-on-Large-Language-Model-based-Autonomous-Agents.html">
            
                <a href="A-Survey-on-Large-Language-Model-based-Autonomous-Agents.html">
            
                    
                    A-Survey-on-Large-Language-Model-based-Autonomous-Agents
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="3.4" data-path="../../Blog/">
            
                <a href="../../Blog/">
            
                    
                    Blog
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="3.4.1" data-path="../../Blog/2024/">
            
                <a href="../../Blog/2024/">
            
                    
                    2024
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="3.4.1.1" data-path="../../Blog/2024/The-Shift-from-Models-to-Compound-AI-Systems.html">
            
                <a href="../../Blog/2024/The-Shift-from-Models-to-Compound-AI-Systems.html">
            
                    
                    The-Shift-from-Models-to-Compound-AI-Systems
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    

            </ul>
            
        </li>
    

    

    <li class="divider"></li>

    <li>
        <a href="https://www.gitbook.com" target="blank" class="gitbook-link">
            本书使用 GitBook 发布
        </a>
    </li>
</ul>


                </nav>
            
        
    </div>

    <div class="book-body">
        
            <div class="body-inner">
                
                    

<div class="book-header" role="navigation">
    

    <!-- Title -->
    <h1>
        <i class="fa fa-circle-o-notch fa-spin"></i>
        <a href="../../.." >A-Survey-on-Large-Language-Model-based-Autonomous-Agents</a>
    </h1>
</div>




                    <div class="page-wrapper" tabindex="-1" role="main">
                        <div class="page-inner">
                            
<div id="book-search-results">
    <div class="search-noresults">
    
                                <section class="normal markdown-section">
                                
                                <div id="anchor-navigation-ex-navbar"><i class="fa fa-navicon"></i><ul><li><span class="title-icon "></span><a href="#a-survey-on-large-language-model-based-autonomous-agents"><b></b>A Survey on Large Language Model based Autonomous Agents</a></li><ul><li><span class="title-icon "></span><a href="#metadata"><b></b>Metadata</a></li><li><span class="title-icon "></span><a href="#summary"><b></b>Summary</a></li><li><span class="title-icon "></span><a href="#introduction"><b></b>Introduction</a></li><li><span class="title-icon "></span><a href="#construction"><b></b>Construction</a></li><ul><li><span class="title-icon "></span><a href="#design"><b></b>Design</a></li><li><span class="title-icon "></span><a href="#agent-capability-acquisition"><b></b>Agent Capability Acquisition</a></li></ul><li><span class="title-icon "></span><a href="#application"><b></b>Application</a></li><li><span class="title-icon "></span><a href="#evaluation"><b></b>Evaluation</a></li><li><span class="title-icon "></span><a href="#challenges"><b></b>Challenges</a></li></ul></ul></div><a href="#a-survey-on-large-language-model-based-autonomous-agents" id="anchorNavigationExGoTop"><i class="fa fa-arrow-up"></i></a><p>2024-05-17</p>
<h1 id="a-survey-on-large-language-model-based-autonomous-agents"><a name="a-survey-on-large-language-model-based-autonomous-agents" class="plugin-anchor" href="#a-survey-on-large-language-model-based-autonomous-agents"><i class="fa fa-link" aria-hidden="true"></i></a><a name="a-survey-on-large-language-model-based-autonomous-agents" class="anchor-navigation-ex-anchor" href="#a-survey-on-large-language-model-based-autonomous-agents"><i class="fa fa-link" aria-hidden="true"></i></a>A Survey on Large Language Model based Autonomous Agents</h1>
<h2 id="metadata"><a name="metadata" class="plugin-anchor" href="#metadata"><i class="fa fa-link" aria-hidden="true"></i></a><a name="metadata" class="anchor-navigation-ex-anchor" href="#metadata"><i class="fa fa-link" aria-hidden="true"></i></a>Metadata</h2>
<p>Lei Wang1, Chen Ma<em>1, Xueyang Feng</em>1, Zeyu Zhang1, Hao Yang1, Jingsen Zhang1, Zhi-Yuan Chen1, Jiakai Tang1, Xu Chen(B)1, Yankai Lin(B)1, Wayne Xin Zhao1, Zhewei Wei1, Ji-Rong Wen1 1 
Gaoling School of Artificial Intelligence, Renmin University of China, Beijing, 100872, China</p>
<h2 id="summary"><a name="summary" class="plugin-anchor" href="#summary"><i class="fa fa-link" aria-hidden="true"></i></a><a name="summary" class="anchor-navigation-ex-anchor" href="#summary"><i class="fa fa-link" aria-hidden="true"></i></a>Summary</h2>
<p>construction of agents, their applications, and methods of evaluation</p>
<h2 id="introduction"><a name="introduction" class="plugin-anchor" href="#introduction"><i class="fa fa-link" aria-hidden="true"></i></a><a name="introduction" class="anchor-navigation-ex-anchor" href="#introduction"><i class="fa fa-link" aria-hidden="true"></i></a>Introduction</h2>
<ul>
<li>traditional agents<ul>
<li>simple and heuristic policy functions</li>
<li>isolated and restricted enviroments</li>
</ul>
</li>
<li>LLM-based agents<ul>
<li>comprehensive internal world knowledge</li>
<li>natural interfaces with humans<blockquote>
<p>&#x201C;key idea is to equip LLMs with crucial human capabilities like memory and planning to make them behave like humans and complete various tasks effectively.&#x201D;</p>
</blockquote>
</li>
</ul>
</li>
</ul>
<h2 id="construction"><a name="construction" class="plugin-anchor" href="#construction"><i class="fa fa-link" aria-hidden="true"></i></a><a name="construction" class="anchor-navigation-ex-anchor" href="#construction"><i class="fa fa-link" aria-hidden="true"></i></a>Construction</h2>
<p><strong>Effectively leverage LLMs:</strong></p>
<ul>
<li>which architecture should be designed to better use LLMs</li>
<li>give the designed architecture, how to enable the agent to acquire capabilities for accomplishing specific tasks</li>
</ul>
<p><strong>Interesting Analogy</strong>
designing the agent architecture &lt;=&gt; determining the network structure
agent capability acquisition &lt;=&gt; learning the network parameters</p>
<h3 id="design"><a name="design" class="plugin-anchor" href="#design"><i class="fa fa-link" aria-hidden="true"></i></a><a name="design" class="anchor-navigation-ex-anchor" href="#design"><i class="fa fa-link" aria-hidden="true"></i></a>Design</h3>
<blockquote>
<p>To bridge the gap between traditional LLMs and autonomous agents, a crucial aspect is to design rational agent architectures to assist LLMs in maximizing their capabilities</p>
</blockquote>
<p><img src="https://s2.loli.net/2024/05/18/BvskeHhIcKUdA2V.png" alt="image.png"></p>
<blockquote>
<p>The purpose of the profiling module is to 
The memory and planning modules place the agent into a dynamic environment, enabling it to recall past behaviors and plan future actions. 
The action module is responsible for translating the agent&#x2019;s decisions into specific outputs.</p>
</blockquote>
<ul>
<li><strong>Profiling Module:</strong> identify the role of the agent. <ul>
<li>handcrafting method: mannual agent profiles<ul>
<li>flexible</li>
<li>labor-intensive</li>
</ul>
</li>
<li>LLM-generation Method: LLM generate<ul>
<li>save labor</li>
<li>lack precise control</li>
</ul>
</li>
<li>Dataset Alignment Method: obtained from real-world datasets</li>
</ul>
</li>
<li><strong>Memory Module:</strong> stores information perceived from the environment and leverages the recorded memories to facilitate future actions<ul>
<li>Structures: short/long-term memory <ul>
<li>Unified Memory: <ul>
<li>in-context learning, short-term memory</li>
<li>memory information is written in prompts</li>
<li>hard to put all memories into prompt</li>
</ul>
</li>
<li>Hybrid Memory:<ul>
<li>prompt(short) and external database(long)</li>
</ul>
</li>
</ul>
</li>
<li>Formats: <ul>
<li>natural language memory: agent behaviors and observations are directly described using raw natural language<ul>
<li>flexible and understandable</li>
<li>rich semantic information</li>
</ul>
</li>
<li>embedding memory: memory information is encoded into embedding vectors<ul>
<li>enhance memory retrieval and reading efficiency</li>
</ul>
</li>
<li>databases: memory information is stored in databases<ul>
<li>utilize SQL</li>
<li>memory module is based on a database</li>
</ul>
</li>
<li>Structured Lists: memory information is organized into lists<ul>
<li>the semantic of memory can be conveyed efficient and concise </li>
</ul>
</li>
</ul>
</li>
<li>Memory Operations: interaction with enviroments<ul>
<li>memory reading: extract meaningful information from memory<ul>
<li>recency, relevance, importance</li>
<li><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>m</mi><mrow><mo>&#x2217;</mo></mrow></msup><mo>=</mo><mi>arg</mi><msub><mi>min</mi><mrow><mi>m</mi><mo>&#x2208;</mo><mi>M</mi></mrow></msub><mi>&#x3B1;</mi><msup><mi>s</mi><mrow><mi>r</mi><mi>e</mi><mi>c</mi></mrow></msup><mo>(</mo><mi>q</mi><mo separator="true">,</mo><mi>m</mi><mo>)</mo><mo>+</mo><mi>&#x3B2;</mi><msup><mi>s</mi><mrow><mi>r</mi><mi>e</mi><mi>l</mi></mrow></msup><mo>(</mo><mi>q</mi><mo separator="true">,</mo><mi>m</mi><mo>)</mo><mo>+</mo><mi>&#x3B3;</mi><msup><mi>s</mi><mrow><mi>i</mi><mi>m</mi><mi>p</mi></mrow></msup><mo>(</mo><mi>m</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">m^{*}=\arg \min _{m \in M} \alpha s^{r e c}(q, m)+\beta s^{r e l}(q, m)+\gamma s^{i m p}(m)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.849108em;"></span><span class="strut bottom" style="height:1.099108em;vertical-align:-0.25em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord mathit">m</span><span class="msupsub"><span class="vlist"><span style="top:-0.363em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span><span class="reset-textstyle scriptstyle uncramped mtight"><span class="mord scriptstyle uncramped mtight"><span class="mord mtight">&#x2217;</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span>&#x200B;</span></span></span></span><span class="mrel">=</span><span class="mop">ar<span style="margin-right:0.01389em;">g</span></span><span class="mop"><span class="mop">min</span><span class="msupsub"><span class="vlist"><span style="top:0.15em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span><span class="reset-textstyle scriptstyle cramped mtight"><span class="mord scriptstyle cramped mtight"><span class="mord mathit mtight">m</span><span class="mrel mtight">&#x2208;</span><span class="mord mathit mtight" style="margin-right:0.10903em;">M</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span>&#x200B;</span></span></span></span><span class="mord mathit" style="margin-right:0.0037em;">&#x3B1;</span><span class="mord"><span class="mord mathit">s</span><span class="msupsub"><span class="vlist"><span style="top:-0.363em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span><span class="reset-textstyle scriptstyle uncramped mtight"><span class="mord scriptstyle uncramped mtight"><span class="mord mathit mtight" style="margin-right:0.02778em;">r</span><span class="mord mathit mtight">e</span><span class="mord mathit mtight">c</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span>&#x200B;</span></span></span></span><span class="mopen">(</span><span class="mord mathit" style="margin-right:0.03588em;">q</span><span class="mpunct">,</span><span class="mord mathit">m</span><span class="mclose">)</span><span class="mbin">+</span><span class="mord mathit" style="margin-right:0.05278em;">&#x3B2;</span><span class="mord"><span class="mord mathit">s</span><span class="msupsub"><span class="vlist"><span style="top:-0.363em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span><span class="reset-textstyle scriptstyle uncramped mtight"><span class="mord scriptstyle uncramped mtight"><span class="mord mathit mtight" style="margin-right:0.02778em;">r</span><span class="mord mathit mtight">e</span><span class="mord mathit mtight" style="margin-right:0.01968em;">l</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span>&#x200B;</span></span></span></span><span class="mopen">(</span><span class="mord mathit" style="margin-right:0.03588em;">q</span><span class="mpunct">,</span><span class="mord mathit">m</span><span class="mclose">)</span><span class="mbin">+</span><span class="mord mathit" style="margin-right:0.05556em;">&#x3B3;</span><span class="mord"><span class="mord mathit">s</span><span class="msupsub"><span class="vlist"><span style="top:-0.363em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span><span class="reset-textstyle scriptstyle uncramped mtight"><span class="mord scriptstyle uncramped mtight"><span class="mord mathit mtight">i</span><span class="mord mathit mtight">m</span><span class="mord mathit mtight">p</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">&#x200B;</span></span>&#x200B;</span></span></span></span><span class="mopen">(</span><span class="mord mathit">m</span><span class="mclose">)</span></span></span></span>, choose m* as the memory to extract.</li>
</ul>
</li>
<li>memory writing:   store information about the perceived environment<ul>
<li>memory duplicated<ul>
<li>using LLM to condense the similar sequences</li>
<li>aggregate via count accumulation</li>
</ul>
</li>
<li>memory overflow: <ul>
<li>user delete</li>
<li>FIFO</li>
</ul>
</li>
</ul>
</li>
<li>memory reflection: summarize into broader and more abstract insights<ul>
<li>(Generative agents) generate questions based on memory -&gt; query memory to obtain relevavnt infomation -&gt; generate five insights</li>
<li>low-level -&gt; high-level</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<blockquote>
<p>The memory module can help the agent to accumulate experiences, self-evolve, and behave in a more consistent, reasonable, and effective manner.</p>
<p>&#x201C;Human memory follows a general progression from sensory memory that registers perceptual inputs, to short-term memory that maintains information transiently, to longterm memory that consolidates information over extended periods.&#x201D;</p>
<p>&#x201C;integrating both short-term and longterm memories can enhance an agent&#x2019;s ability for long-range reasoning and accumulation of valuable experiences, which are crucial for accomplishing tasks in complex environments&#x201D;</p>
<p>&#x201C;The memory module plays a critical role in allowing the agent to acquire, accumulate, and utilize significant knowledge by interacting with the environment&#x201D;</p>
</blockquote>
<ul>
<li><p><strong>Planning Module</strong>: deconstruct into simpler subtasks and solve them independently</p>
<ul>
<li>without feedback<ul>
<li>Single-path Reasoning: each step leading to only one subsequent step<ul>
<li>Chain of Thought: proposes inputting reasoning steps for solving complex problems into the prompt</li>
</ul>
</li>
<li>Multi-path Reasoning: the reasoning steps organized into a tree-like structure<ul>
<li>using a tree-like reasoning structure</li>
<li>COT-SC, ToT</li>
</ul>
</li>
<li>external planners: generate plans for domain-specific problems</li>
</ul>
</li>
<li>with feedback<ul>
<li>environment<ul>
<li>thought-act-observation (ReAct)</li>
<li>intermediate progress of execution, execution error, self-verification (Voyager)</li>
<li>environment states and executed action information</li>
</ul>
</li>
<li>human<ul>
<li>make the agent align with the human values and preferences</li>
<li>alleviate the hallucination problem</li>
</ul>
</li>
<li>model<ul>
<li>output-feedback-refinement<blockquote>
<p>&#x201C;CO-LLM demonstrates that LLMs is good at generating high-level plans, but struggle with low-level control. To address this limitation, a heuristically designed external low-level planner is employed to effectively execute actions based on high-level plans.</p>
</blockquote>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p><strong>Action Module</strong>: interacts with the environment</p>
<ul>
<li>Action goal<ul>
<li>Task completion: to complete specific task</li>
<li>Communication: to communicate with agents or humans</li>
<li>Environment exploration: to explore unfamiliar environments to expand its perception</li>
</ul>
</li>
<li><p>Action production</p>
<ul>
<li>Action via Memory Recollection: generated by memory and task</li>
<li>Action via Plan Following: pre-generated plans<ul>
<li>generate action plans first</li>
<li>decomposing the task into sub-goals and make plans.</li>
</ul>
</li>
</ul>
</li>
<li><p>Action space: the set of possible actions</p>
<ul>
<li>external tools: call external tools for executing action<ul>
<li>APIs: existing APIs, API invoked by LLM</li>
<li>Databases &amp; knowledge Bases</li>
<li>External Models: incorporates other models </li>
</ul>
</li>
<li>inernal knowledge of LLMs<ul>
<li>capabilities of LLMs: plan, conversation, understanding</li>
</ul>
</li>
</ul>
</li>
<li>Action impact<ul>
<li>Change environment</li>
<li>Alter internal states</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="agent-capability-acquisition"><a name="agent-capability-acquisition" class="plugin-anchor" href="#agent-capability-acquisition"><i class="fa fa-link" aria-hidden="true"></i></a><a name="agent-capability-acquisition" class="anchor-navigation-ex-anchor" href="#agent-capability-acquisition"><i class="fa fa-link" aria-hidden="true"></i></a>Agent Capability Acquisition</h3>
<blockquote>
<p>The architecture functions as the &#x201C;hardware&#x201D; of the agent. 
The agent may lack the necessary <strong>task-specific capabilities</strong>, skills and experiences, which can be regarded as &quot;software&quot; resources.</p>
</blockquote>
<ul>
<li>Capability Acquisition with Fine-tuning<ul>
<li>Human Annotated Datasets: align with humans, costly</li>
<li>LLM Generated Datasets: cheap</li>
<li>Real-world Datasets</li>
</ul>
</li>
<li>Capability Acquisition without Fine-tuning<ul>
<li>Prompt engineering<ul>
<li>CoT-like</li>
<li>agent beliefs about mental states</li>
<li>inject reflections</li>
</ul>
</li>
<li>Mechanism Engineering<ul>
<li>Trial-and-error: action-judge-error-incorporate feedbacks</li>
<li>Crowd-sourcing: multi agents learn from each other&apos;s idea to reach consensus</li>
<li>Experience Accumulation: extract past memory to solve similar task</li>
<li>Self-driven Evolution</li>
</ul>
</li>
</ul>
</li>
</ul>
<blockquote>
<p>In the era of agents, the model capability can be acquired based on three strategies:(1) model fine-tuning, (2) prompt engineer and (3) designing proper agent evolution mechanisms</p>
</blockquote>
<p><img src="https://s2.loli.net/2024/05/18/eGopk93StVDi8IZ.png" alt="image.png"></p>
<h2 id="application"><a name="application" class="plugin-anchor" href="#application"><i class="fa fa-link" aria-hidden="true"></i></a><a name="application" class="anchor-navigation-ex-anchor" href="#application"><i class="fa fa-link" aria-hidden="true"></i></a>Application</h2>
<ul>
<li>social science<ul>
<li>psychology: different profiles</li>
<li>political science and economy: predict voting, political speech, economic behavior</li>
<li>social simulation</li>
<li>jurisprudence</li>
<li>research assistant</li>
</ul>
</li>
<li>natural science<ul>
<li>documentation and data management</li>
<li>experiment assistant</li>
<li>education</li>
</ul>
</li>
<li>engineering<ul>
<li>civil engineering: design</li>
<li>cs &amp; se: code</li>
<li>industrial automation: control of procedure</li>
<li>robotics &amp; embodied: plan, reason, collaborate</li>
</ul>
</li>
<li>libraries to easily implement/evaluate:<ul>
<li>LangChain: automates coding, testing, debugging and documentation</li>
<li>XLang, AutoGPT...</li>
</ul>
</li>
</ul>
<h2 id="evaluation"><a name="evaluation" class="plugin-anchor" href="#evaluation"><i class="fa fa-link" aria-hidden="true"></i></a><a name="evaluation" class="anchor-navigation-ex-anchor" href="#evaluation"><i class="fa fa-link" aria-hidden="true"></i></a>Evaluation</h2>
<ul>
<li>subjective evaluation<ul>
<li>human annotation: human score or rank</li>
<li>Turing Test: separate the outputs by humans and agents</li>
<li>use of LLMs</li>
</ul>
</li>
<li>objective evaluation<ul>
<li>metrics<ul>
<li>Task success metrics</li>
<li>Human similarity metrics</li>
<li>Efficiency metrics<ul>
<li>length of planning</li>
<li>cost associated with devolopment</li>
<li>speed of inference</li>
<li>number of clarification dialogue</li>
</ul>
</li>
</ul>
</li>
<li>Protocols: how to leverage these metrics to evaluate the capability<ul>
<li>Real-world simulation: in real environments</li>
<li>Social evaluation: assess social intelligence based on agent interaction</li>
<li>Multi-task evaluation: generalization capability</li>
<li>Software testing</li>
</ul>
</li>
<li>Benchmarks
<img src="https://s2.loli.net/2024/05/18/KV9oYa81DtyFgCS.png" alt="image.png"></li>
</ul>
</li>
</ul>
<h2 id="challenges"><a name="challenges" class="plugin-anchor" href="#challenges"><i class="fa fa-link" aria-hidden="true"></i></a><a name="challenges" class="anchor-navigation-ex-anchor" href="#challenges"><i class="fa fa-link" aria-hidden="true"></i></a>Challenges</h2>
<ul>
<li>role-playing capability<ul>
<li>fine-tuning</li>
<li>design tailored agent prompts/architecture</li>
</ul>
</li>
</ul>
<blockquote>
<p>&#x201C;In addition, previous research [30] has shown that existing LLMs may not well model the human cognitive psychology characters, leading to the lack of self-awareness in conversation scenarios&#x201D; (Wang &#x7B49;, 2024, p. 32)</p>
</blockquote>
<ul>
<li><p>Generalized Human Alignment</p>
<blockquote>
<p>when the agents are leveraged for real-world simulation, an ideal simulator should be able to honestly depict diverse human traits, including the ones with incorrect values.</p>
</blockquote>
</li>
<li><p>Prompt Robustness</p>
<blockquote>
<p>agents, as they encompass not a single prompt but a prompt framework that considers all modules, wherein the prompt for one module has the potential to influence others.</p>
</blockquote>
</li>
<li><p>Hallucination</p>
<ul>
<li>incorporating human correction feedback</li>
</ul>
</li>
<li><p>Knowledge Boundary</p>
<ul>
<li>how to simulate diverse real-world human behaviors?</li>
<li>constrain the utilization of user-unknown knowledge of LLM<blockquote>
<p>LLMs may make decisions based on their extensive knowledge, even though real-world users would not have access to the contents</p>
</blockquote>
</li>
</ul>
</li>
<li><p>Efficiency</p>
<ul>
<li>inference</li>
<li>extract memory</li>
<li>make plans before taking actions</li>
<li>...</li>
</ul>
</li>
</ul>
<footer class="page-footer"><span class="copyright">Copyright &#xA9; &#x7248;&#x6743;&#x4FE1;&#x606F; all right reserved&#xFF0C;powered by Gitbook</span><span class="footer-modification">&#x8BE5;&#x6587;&#x4EF6;&#x4FEE;&#x8BA2;&#x65F6;&#x95F4;&#xFF1A;
2024-05-18 15:03:41
</span></footer>
                                
                                </section>
                            
    </div>
    <div class="search-results">
        <div class="has-results">
            
            <h1 class="search-results-title"><span class='search-results-count'></span> results matching "<span class='search-query'></span>"</h1>
            <ul class="search-results-list"></ul>
            
        </div>
        <div class="no-results">
            
            <h1 class="search-results-title">No results matching "<span class='search-query'></span>"</h1>
            
        </div>
    </div>
</div>

                        </div>
                    </div>
                
            </div>

            
                
                <a href="The-Landscape-of-Emerging-AI-Agent-Architectures-for-Reasoning-Planning-and-Tool-Calling-A-Survey.html" class="navigation navigation-prev " aria-label="Previous page: The-Landscape-of-Emerging-AI-Agent-Architectures-for-Reasoning-Planning-and-Tool-Calling-A-Survey">
                    <i class="fa fa-angle-left"></i>
                </a>
                
                
                <a href="../../Blog/" class="navigation navigation-next " aria-label="Next page: Blog">
                    <i class="fa fa-angle-right"></i>
                </a>
                
            
        
    </div>

    <script>
        var gitbook = gitbook || [];
        gitbook.push(function() {
            gitbook.page.hasChanged({"page":{"title":"A-Survey-on-Large-Language-Model-based-Autonomous-Agents","level":"3.3.1.2","depth":3,"next":{"title":"Blog","level":"3.4","depth":1,"path":"Notes/Blog/README.md","ref":"Notes/Blog/README.md","articles":[{"title":"2024","level":"3.4.1","depth":2,"path":"Notes/Blog/2024/README.md","ref":"Notes/Blog/2024/README.md","articles":[{"title":"The-Shift-from-Models-to-Compound-AI-Systems","level":"3.4.1.1","depth":3,"path":"Notes/Blog/2024/The-Shift-from-Models-to-Compound-AI-Systems.md","ref":"Notes/Blog/2024/The-Shift-from-Models-to-Compound-AI-Systems.md","articles":[]}]}]},"previous":{"title":"The-Landscape-of-Emerging-AI-Agent-Architectures-for-Reasoning-Planning-and-Tool-Calling-A-Survey","level":"3.3.1.1","depth":3,"path":"Notes/Arxiv/2024/The-Landscape-of-Emerging-AI-Agent-Architectures-for-Reasoning-Planning-and-Tool-Calling-A-Survey.md","ref":"Notes/Arxiv/2024/The-Landscape-of-Emerging-AI-Agent-Architectures-for-Reasoning-Planning-and-Tool-Calling-A-Survey.md","articles":[]},"dir":"ltr"},"config":{"plugins":["-lunr","-search","-sharing","highlight","livereload","search-pro","expandable-chapters-small","splitter","github","hide-element","code","anchor-navigation-ex","tbfed-pagefooter","autotheme","anchors","disqus","katex"],"root":".","styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"},"pluginsConfig":{"tbfed-pagefooter":{"copyright":"Copyright &copy 版权信息","modify_label":"该文件修订时间：","modify_format":"YYYY-MM-DD HH:mm:ss"},"disqus":{"useIdentifier":false,"shortName":"https-www-dakaian-com-awesome-papers"},"github":{"url":"https://github.com/andakai/awesome-papers"},"livereload":{},"splitter":{},"search-pro":{},"code":{"copyButtons":true},"hide-element":{"elements":[".gitbook-link"]},"katex":{},"fontsettings":{"family":"serif","size":2,"theme":"white"},"highlight":{},"anchor-navigation-ex":{"showLevelIcon":false,"mode":"float","pageTop":{"level1Icon":"","level2Icon":"","level3Icon":"","showLevelIcon":false},"showLevel":false,"tocLevel1Icon":"fa fa-hand-o-right","tocLevel2Icon":"fa fa-hand-o-right","tocLevel3Icon":"fa fa-hand-o-right","showGoTop":true,"printLog":false,"multipleH1":false,"multipleH2":false,"associatedWithSummary":true,"multipleH3":false,"float":{"floatIcon":"fa fa-navicon","level1Icon":"","level2Icon":"","level3Icon":"","showLevelIcon":false},"multipleH4":false},"expandable-chapters-small":{},"autotheme":{"night":[20,21,22,23,0,1,2,3,4,5],"sepia":[6,7,8,17,18,19],"white":[9,10,11,12,13,14,15,16]},"theme-default":{"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"},"showLevel":false},"anchors":{}},"theme":"default","author":"Dakai","pdf":{"pageNumbers":true,"fontSize":12,"fontFamily":"Arial","paperSize":"a4","chapterMark":"pagebreak","pageBreaksBefore":"/","margin":{"right":62,"left":62,"top":56,"bottom":56}},"structure":{"langs":"LANGS.md","readme":"README.md","glossary":"GLOSSARY.md","summary":"SUMMARY.md"},"variables":{},"title":"awesome-papers","language":"zh-hans","output.name":"site","links":{"sidebar":{"我的个人博客":"https://andakai.github.io/"}},"gitbook":"3.2.3","description":"dakai's awesome-papers"},"file":{"path":"Notes/Arxiv/2024/A-Survey-on-Large-Language-Model-based-Autonomous-Agents.md","mtime":"2024-05-18T07:03:41.062Z","type":"markdown"},"gitbook":{"version":"3.2.3","time":"2024-05-20T17:31:52.493Z"},"basePath":"../../..","book":{"language":""}});
        });
    </script>
</div>

        
    <script src="../../../gitbook/gitbook.js"></script>
    <script src="../../../gitbook/theme.js"></script>
    
        
        <script src="../../../gitbook/gitbook-plugin-livereload/plugin.js"></script>
        
    
        
        <script src="../../../gitbook/gitbook-plugin-search-pro/jquery.mark.min.js"></script>
        
    
        
        <script src="../../../gitbook/gitbook-plugin-search-pro/search.js"></script>
        
    
        
        <script src="../../../gitbook/gitbook-plugin-expandable-chapters-small/expandable-chapters-small.js"></script>
        
    
        
        <script src="../../../gitbook/gitbook-plugin-splitter/splitter.js"></script>
        
    
        
        <script src="../../../gitbook/gitbook-plugin-github/plugin.js"></script>
        
    
        
        <script src="../../../gitbook/gitbook-plugin-hide-element/plugin.js"></script>
        
    
        
        <script src="../../../gitbook/gitbook-plugin-code/plugin.js"></script>
        
    
        
        <script src="../../../gitbook/gitbook-plugin-autotheme/plugin.js"></script>
        
    
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/URI.js/1.16.1/URI.min.js"></script>
        
    
        
        <script src="../../../gitbook/gitbook-plugin-disqus/plugin.js"></script>
        
    
        
        <script src="../../../gitbook/gitbook-plugin-fontsettings/fontsettings.js"></script>
        
    

    </body>
</html>

