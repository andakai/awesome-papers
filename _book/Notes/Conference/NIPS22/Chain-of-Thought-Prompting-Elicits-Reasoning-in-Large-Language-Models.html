
<!DOCTYPE HTML>
<html lang="zh-hans" >
    <head>
        <meta charset="UTF-8">
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <title>Chain-of-Thought-Prompting-Elicits-Reasoning-in-Large-Language-Models · awesome-papers</title>
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <meta name="description" content="">
        <meta name="generator" content="GitBook 3.2.3">
        <meta name="author" content="Dakai">
        
        
    
    <link rel="stylesheet" href="../../../gitbook/style.css">

    
            
                
                <link rel="stylesheet" href="../../../gitbook/gitbook-plugin-highlight/website.css">
                
            
                
                <link rel="stylesheet" href="../../../gitbook/gitbook-plugin-search-pro/search.css">
                
            
                
                <link rel="stylesheet" href="../../../gitbook/gitbook-plugin-expandable-chapters-small/expandable-chapters-small.css">
                
            
                
                <link rel="stylesheet" href="../../../gitbook/gitbook-plugin-splitter/splitter.css">
                
            
                
                <link rel="stylesheet" href="../../../gitbook/gitbook-plugin-code/plugin.css">
                
            
                
                <link rel="stylesheet" href="../../../gitbook/gitbook-plugin-anchor-navigation-ex/style/plugin.css">
                
            
                
                <link rel="stylesheet" href="../../../gitbook/gitbook-plugin-tbfed-pagefooter/footer.css">
                
            
                
                <link rel="stylesheet" href="../../../gitbook/gitbook-plugin-anchors/plugin.css">
                
            
                
                <link rel="stylesheet" href="../../../gitbook/gitbook-plugin-disqus/plugin.css">
                
            
                
                <link rel="stylesheet" href="../../../gitbook/gitbook-plugin-katex/katex.min.css">
                
            
                
                <link rel="stylesheet" href="../../../gitbook/gitbook-plugin-fontsettings/website.css">
                
            
        

    

    
        
    
        
    
        
    
        
    
        
    
        
    

        
    
    
    <meta name="HandheldFriendly" content="true"/>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <link rel="apple-touch-icon-precomposed" sizes="152x152" href="../../../gitbook/images/apple-touch-icon-precomposed-152.png">
    <link rel="shortcut icon" href="../../../gitbook/images/favicon.ico" type="image/x-icon">

    
    <link rel="next" href="../../Journal/" />
    
    
    <link rel="prev" href="WebShop-Towards-Scalable-Real-World-Web-Interaction-with-Grounded-Language-Agents.html" />
    

    </head>
    <body>
        
<div class="book">
    <div class="book-summary">
        
            
<div id="book-search-input" role="search">
    <input type="text" placeholder="输入并搜索" />
</div>

            
                <nav role="navigation">
                


<ul class="summary">
    
    
    
        
        <li>
            <a href="https://andakai.github.io/" target="_blank" class="custom-link">我的个人博客</a>
        </li>
    
    

    
    <li class="divider"></li>
    

    
        
        
    
        <li class="chapter " data-level="1.1" data-path="../../../">
            
                <a href="../../../">
            
                    
                    Introduction
            
                </a>
            

            
        </li>
    

    
        
        <li class="header">PAPER LIST</li>
        
        
    
        <li class="chapter " data-level="2.1" data-path="../../../Lists/MLSYS/">
            
                <a href="../../../Lists/MLSYS/">
            
                    
                    MLSYS
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="2.1.1" data-path="../../../Lists/MLSYS/LLM/">
            
                <a href="../../../Lists/MLSYS/LLM/">
            
                    
                    LLM
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.1.2" data-path="../../../Lists/MLSYS/Agent/">
            
                <a href="../../../Lists/MLSYS/Agent/">
            
                    
                    Agent
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.1.3" data-path="../../../Lists/MLSYS/RAG/">
            
                <a href="../../../Lists/MLSYS/RAG/">
            
                    
                    RAG
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    

    
        
        <li class="header">READING NOTES</li>
        
        
    
        <li class="chapter " data-level="3.1" data-path="../">
            
                <a href="../">
            
                    
                    Conference
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="3.1.1" data-path="../ICLR23/">
            
                <a href="../ICLR23/">
            
                    
                    ICLR23
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="3.1.1.1" data-path="../ICLR23/ReAct-Synergizing-Reasoning-and-Acting-in-Language-Models.html">
            
                <a href="../ICLR23/ReAct-Synergizing-Reasoning-and-Acting-in-Language-Models.html">
            
                    
                    ReAct-Synergizing-Reasoning-and-Acting-in-Language-Models
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="3.1.2" data-path="../NIPS23/">
            
                <a href="../NIPS23/">
            
                    
                    NIPS23
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="3.1.2.1" data-path="../NIPS23/InterCode-Standardizing-and-Benchmarking-Interactive-Coding-with-Execution-Feedback.html">
            
                <a href="../NIPS23/InterCode-Standardizing-and-Benchmarking-Interactive-Coding-with-Execution-Feedback.html">
            
                    
                    InterCode-Standardizing-and-Benchmarking-Interactive-Coding-with-Execution-Feedback
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="3.1.2.2" data-path="../NIPS23/Reflexion-Language-Agents-with-Verbal-Reinforcement-Learning.html">
            
                <a href="../NIPS23/Reflexion-Language-Agents-with-Verbal-Reinforcement-Learning.html">
            
                    
                    Reflexion-Language-Agents-with-Verbal-Reinforcement-Learning
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="3.1.3" data-path="./">
            
                <a href="./">
            
                    
                    NIPS22
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="3.1.3.1" data-path="WebShop-Towards-Scalable-Real-World-Web-Interaction-with-Grounded-Language-Agents.html">
            
                <a href="WebShop-Towards-Scalable-Real-World-Web-Interaction-with-Grounded-Language-Agents.html">
            
                    
                    WebShop-Towards-Scalable-Real-World-Web-Interaction-with-Grounded-Language-Agents
            
                </a>
            

            
        </li>
    
        <li class="chapter active" data-level="3.1.3.2" data-path="Chain-of-Thought-Prompting-Elicits-Reasoning-in-Large-Language-Models.html">
            
                <a href="Chain-of-Thought-Prompting-Elicits-Reasoning-in-Large-Language-Models.html">
            
                    
                    Chain-of-Thought-Prompting-Elicits-Reasoning-in-Large-Language-Models
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="3.2" data-path="../../Journal/">
            
                <a href="../../Journal/">
            
                    
                    Journal
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="3.3" data-path="../../Arxiv/">
            
                <a href="../../Arxiv/">
            
                    
                    Arxiv
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="3.3.1" data-path="../../Arxiv/2024/">
            
                <a href="../../Arxiv/2024/">
            
                    
                    2024
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="3.3.1.1" data-path="../../Arxiv/2024/The-Landscape-of-Emerging-AI-Agent-Architectures-for-Reasoning-Planning-and-Tool-Calling-A-Survey.html">
            
                <a href="../../Arxiv/2024/The-Landscape-of-Emerging-AI-Agent-Architectures-for-Reasoning-Planning-and-Tool-Calling-A-Survey.html">
            
                    
                    The-Landscape-of-Emerging-AI-Agent-Architectures-for-Reasoning-Planning-and-Tool-Calling-A-Survey
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="3.3.1.2" data-path="../../Arxiv/2024/A-Survey-on-Large-Language-Model-based-Autonomous-Agents.html">
            
                <a href="../../Arxiv/2024/A-Survey-on-Large-Language-Model-based-Autonomous-Agents.html">
            
                    
                    A-Survey-on-Large-Language-Model-based-Autonomous-Agents
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="3.3.2" data-path="../../Arxiv/2023/">
            
                <a href="../../Arxiv/2023/">
            
                    
                    2023
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="3.3.2.1" data-path="../../Arxiv/2023/Retrieval-Augmented-Generation-for-AI-Generated-Content-A-Survey.html">
            
                <a href="../../Arxiv/2023/Retrieval-Augmented-Generation-for-AI-Generated-Content-A-Survey.html">
            
                    
                    Retrieval-Augmented-Generation-for-AI-Generated-Content-A-Survey
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="3.4" data-path="../../Blog/">
            
                <a href="../../Blog/">
            
                    
                    Blog
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="3.4.1" data-path="../../Blog/2024/">
            
                <a href="../../Blog/2024/">
            
                    
                    2024
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="3.4.1.1" data-path="../../Blog/2024/The-Shift-from-Models-to-Compound-AI-Systems.html">
            
                <a href="../../Blog/2024/The-Shift-from-Models-to-Compound-AI-Systems.html">
            
                    
                    The-Shift-from-Models-to-Compound-AI-Systems
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    

            </ul>
            
        </li>
    

    

    <li class="divider"></li>

    <li>
        <a href="https://www.gitbook.com" target="blank" class="gitbook-link">
            本书使用 GitBook 发布
        </a>
    </li>
</ul>


                </nav>
            
        
    </div>

    <div class="book-body">
        
            <div class="body-inner">
                
                    

<div class="book-header" role="navigation">
    

    <!-- Title -->
    <h1>
        <i class="fa fa-circle-o-notch fa-spin"></i>
        <a href="../../.." >Chain-of-Thought-Prompting-Elicits-Reasoning-in-Large-Language-Models</a>
    </h1>
</div>




                    <div class="page-wrapper" tabindex="-1" role="main">
                        <div class="page-inner">
                            
<div id="book-search-results">
    <div class="search-noresults">
    
                                <section class="normal markdown-section">
                                
                                <div id="anchor-navigation-ex-navbar"><i class="fa fa-navicon"></i><ul><li><span class="title-icon "></span><a href="#chain-of-thought-prompting-elicits-reasoning-in-large-language-models"><b></b>Chain-of-Thought Prompting Elicits Reasoning in Large Language Models</a></li><ul><li><span class="title-icon "></span><a href="#summary"><b></b>Summary</a></li><li><span class="title-icon "></span><a href="#evaluation"><b></b>Evaluation</a></li><li><span class="title-icon "></span><a href="#strengths-and-weaknesses"><b></b>Strengths and Weaknesses</a></li><li><span class="title-icon "></span><a href="#further-ideas"><b></b>Further Ideas</a></li></ul></ul></div><a href="#chain-of-thought-prompting-elicits-reasoning-in-large-language-models" id="anchorNavigationExGoTop"><i class="fa fa-arrow-up"></i></a><h1 id="chain-of-thought-prompting-elicits-reasoning-in-large-language-models"><a name="chain-of-thought-prompting-elicits-reasoning-in-large-language-models" class="plugin-anchor" href="#chain-of-thought-prompting-elicits-reasoning-in-large-language-models"><i class="fa fa-link" aria-hidden="true"></i></a><a name="chain-of-thought-prompting-elicits-reasoning-in-large-language-models" class="anchor-navigation-ex-anchor" href="#chain-of-thought-prompting-elicits-reasoning-in-large-language-models"><i class="fa fa-link" aria-hidden="true"></i></a>Chain-of-Thought Prompting Elicits Reasoning in Large Language Models</h1>
<p>2024-05-20</p>
<h2 id="summary"><a name="summary" class="plugin-anchor" href="#summary"><i class="fa fa-link" aria-hidden="true"></i></a><a name="summary" class="anchor-navigation-ex-anchor" href="#summary"><i class="fa fa-link" aria-hidden="true"></i></a>Summary</h2>
<p>It tries to mimic a step-by-step thought process for arriving at the answer as humans. So it manually composed a set of few-shot exemplars with chains of thought for prompting. This can guide the LLM to do chain-of-thought, which largely improves the performance in various datasets. This phenomenon only emerge as the LLM model becomes as large as hundreds of Bs and for those problems which need complicated reasoning.</p>
<h2 id="evaluation"><a name="evaluation" class="plugin-anchor" href="#evaluation"><i class="fa fa-link" aria-hidden="true"></i></a><a name="evaluation" class="anchor-navigation-ex-anchor" href="#evaluation"><i class="fa fa-link" aria-hidden="true"></i></a>Evaluation</h2>
<p>This paper does experiments on arithmetic reasoning, commonsense reasoning, symbolic reasoning.
<img src="https://s2.loli.net/2024/05/21/2BQKMO1UjhZIdTa.png" alt="image.png">
Let&apos;s emphasize on its ablation study of arithmetic. This part analyses probably why CoT works.</p>
<ul>
<li>Equation only:<ul>
<li>To test whether the math equation helps.</li>
<li>setup: the output is only a mathematical equation before the answer</li>
<li>no effect when the question is complicated</li>
</ul>
</li>
<li>Variable compute only:<ul>
<li>To test whether the computation helps.</li>
<li>setup: the output is replaced with <code>...</code> equal to the total length</li>
<li>no effect</li>
</ul>
</li>
<li>Chain of thought after answer:<ul>
<li>To test the CoT is not reasoning, but can better access relevant knowledge.</li>
<li>setup: put the CoT prompts after the answer (So that when giving the answer, the LLM doesn&apos;t rely on the CoT, but CoT process is still inserted into the LLM. The similar idea is adding &quot;think step by step in the end&quot;)</li>
<li>no effect.</li>
</ul>
</li>
</ul>
<p>The robustness is concluded by different anatators writing the CoT prompts.
OOD evaluation reveals the CoT can facilitate length generalization.</p>
<h2 id="strengths-and-weaknesses"><a name="strengths-and-weaknesses" class="plugin-anchor" href="#strengths-and-weaknesses"><i class="fa fa-link" aria-hidden="true"></i></a><a name="strengths-and-weaknesses" class="anchor-navigation-ex-anchor" href="#strengths-and-weaknesses"><i class="fa fa-link" aria-hidden="true"></i></a>Strengths and Weaknesses</h2>
<p>Strengths:</p>
<ul>
<li>Good prompt engineering</li>
<li>I think the evaluation and the analysis are nice. It discusses the inner reasons about CoT.</li>
</ul>
<p>Weaknesses:</p>
<ul>
<li>This paper doesn&apos;t answer whether the neural network is reasoning</li>
<li>Manually doing CoT exemplars is prohibitive for finetuning</li>
<li>No guarantee of correct reasoning path</li>
<li>Only emerge in large models</li>
<li>(The above is given in the paper already)<h2 id="further-ideas"><a name="further-ideas" class="plugin-anchor" href="#further-ideas"><i class="fa fa-link" aria-hidden="true"></i></a><a name="further-ideas" class="anchor-navigation-ex-anchor" href="#further-ideas"><i class="fa fa-link" aria-hidden="true"></i></a>Further Ideas</h2>
</li>
<li>I didn&apos;t know such prompt method before. I think it is very inspiring, making people to  think about Is the LLM really reasoning? I am still curious about the third ablation study-Chain of thought after answer. If there exists a completely perfect LLM, give it a prompt, no matter there is a CoT exemplar or not, this LLM will give the right answer. oh we can compare the best LLM to the best optimizer, and other worse optimizers may arrive at a local-best but not a global-best point. Maybe CoT gives a good start to optimize to the best point or a better optimizer. (not accurate analogy). All in all, what I want to express is that, if we have a perfect LLM, there may be no need to do prompt engineering, the LLM itself can reach the right answer. But as the imperfect LLMs can reach the right answer, so the reasoning path itself may already be in the LLM, but CoT makes it clear. In addition, humans mostly won&apos;t speak out exactly what they are reasoning. The reasoning process is inside the LLM, maybe some key processes can be spoken out but omit some easy ones. In LLM, if we can find the reasoning path inside the LLM, the exemplar prefill and the reasoning decode overhead can be avoided. (random thoughts) </li>
</ul>
<footer class="page-footer"><span class="copyright">Copyright &#xA9; &#x7248;&#x6743;&#x4FE1;&#x606F; all right reserved&#xFF0C;powered by Gitbook</span><span class="footer-modification">&#x8BE5;&#x6587;&#x4EF6;&#x4FEE;&#x8BA2;&#x65F6;&#x95F4;&#xFF1A;
2024-05-21 01:38:43
</span></footer>
                                
                                </section>
                            
    </div>
    <div class="search-results">
        <div class="has-results">
            
            <h1 class="search-results-title"><span class='search-results-count'></span> results matching "<span class='search-query'></span>"</h1>
            <ul class="search-results-list"></ul>
            
        </div>
        <div class="no-results">
            
            <h1 class="search-results-title">No results matching "<span class='search-query'></span>"</h1>
            
        </div>
    </div>
</div>

                        </div>
                    </div>
                
            </div>

            
                
                <a href="WebShop-Towards-Scalable-Real-World-Web-Interaction-with-Grounded-Language-Agents.html" class="navigation navigation-prev " aria-label="Previous page: WebShop-Towards-Scalable-Real-World-Web-Interaction-with-Grounded-Language-Agents">
                    <i class="fa fa-angle-left"></i>
                </a>
                
                
                <a href="../../Journal/" class="navigation navigation-next " aria-label="Next page: Journal">
                    <i class="fa fa-angle-right"></i>
                </a>
                
            
        
    </div>

    <script>
        var gitbook = gitbook || [];
        gitbook.push(function() {
            gitbook.page.hasChanged({"page":{"title":"Chain-of-Thought-Prompting-Elicits-Reasoning-in-Large-Language-Models","level":"3.1.3.2","depth":3,"next":{"title":"Journal","level":"3.2","depth":1,"path":"Notes/Journal/README.md","ref":"Notes/Journal/README.md","articles":[]},"previous":{"title":"WebShop-Towards-Scalable-Real-World-Web-Interaction-with-Grounded-Language-Agents","level":"3.1.3.1","depth":3,"path":"Notes/Conference/NIPS22/WebShop-Towards-Scalable-Real-World-Web-Interaction-with-Grounded-Language-Agents.md","ref":"Notes/Conference/NIPS22/WebShop-Towards-Scalable-Real-World-Web-Interaction-with-Grounded-Language-Agents.md","articles":[]},"dir":"ltr"},"config":{"plugins":["-lunr","-search","-sharing","highlight","livereload","search-pro","expandable-chapters-small","splitter","github","hide-element","code","anchor-navigation-ex","tbfed-pagefooter","autotheme","anchors","disqus","katex"],"root":".","styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"},"pluginsConfig":{"tbfed-pagefooter":{"copyright":"Copyright &copy 版权信息","modify_label":"该文件修订时间：","modify_format":"YYYY-MM-DD HH:mm:ss"},"disqus":{"useIdentifier":false,"shortName":"https-www-dakaian-com-awesome-papers"},"github":{"url":"https://github.com/andakai/awesome-papers"},"livereload":{},"splitter":{},"search-pro":{},"code":{"copyButtons":true},"hide-element":{"elements":[".gitbook-link"]},"katex":{},"fontsettings":{"family":"serif","size":2,"theme":"white"},"highlight":{},"anchor-navigation-ex":{"showLevelIcon":false,"mode":"float","pageTop":{"level1Icon":"","level2Icon":"","level3Icon":"","showLevelIcon":false},"showLevel":false,"tocLevel1Icon":"fa fa-hand-o-right","tocLevel2Icon":"fa fa-hand-o-right","tocLevel3Icon":"fa fa-hand-o-right","showGoTop":true,"printLog":false,"multipleH1":false,"multipleH2":false,"associatedWithSummary":true,"multipleH3":false,"float":{"floatIcon":"fa fa-navicon","level1Icon":"","level2Icon":"","level3Icon":"","showLevelIcon":false},"multipleH4":false},"expandable-chapters-small":{},"autotheme":{"night":[20,21,22,23,0,1,2,3,4,5],"sepia":[6,7,8,17,18,19],"white":[9,10,11,12,13,14,15,16]},"theme-default":{"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"},"showLevel":false},"anchors":{}},"theme":"default","author":"Dakai","pdf":{"pageNumbers":true,"fontSize":12,"fontFamily":"Arial","paperSize":"a4","chapterMark":"pagebreak","pageBreaksBefore":"/","margin":{"right":62,"left":62,"top":56,"bottom":56}},"structure":{"langs":"LANGS.md","readme":"README.md","glossary":"GLOSSARY.md","summary":"SUMMARY.md"},"variables":{},"title":"awesome-papers","language":"zh-hans","output.name":"site","links":{"sidebar":{"我的个人博客":"https://andakai.github.io/"}},"gitbook":"3.2.3","description":"dakai's awesome-papers"},"file":{"path":"Notes/Conference/NIPS22/Chain-of-Thought-Prompting-Elicits-Reasoning-in-Large-Language-Models.md","mtime":"2024-05-20T17:38:43.388Z","type":"markdown"},"gitbook":{"version":"3.2.3","time":"2024-05-22T17:52:48.945Z"},"basePath":"../../..","book":{"language":""}});
        });
    </script>
</div>

        
    <script src="../../../gitbook/gitbook.js"></script>
    <script src="../../../gitbook/theme.js"></script>
    
        
        <script src="../../../gitbook/gitbook-plugin-livereload/plugin.js"></script>
        
    
        
        <script src="../../../gitbook/gitbook-plugin-search-pro/jquery.mark.min.js"></script>
        
    
        
        <script src="../../../gitbook/gitbook-plugin-search-pro/search.js"></script>
        
    
        
        <script src="../../../gitbook/gitbook-plugin-expandable-chapters-small/expandable-chapters-small.js"></script>
        
    
        
        <script src="../../../gitbook/gitbook-plugin-splitter/splitter.js"></script>
        
    
        
        <script src="../../../gitbook/gitbook-plugin-github/plugin.js"></script>
        
    
        
        <script src="../../../gitbook/gitbook-plugin-hide-element/plugin.js"></script>
        
    
        
        <script src="../../../gitbook/gitbook-plugin-code/plugin.js"></script>
        
    
        
        <script src="../../../gitbook/gitbook-plugin-autotheme/plugin.js"></script>
        
    
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/URI.js/1.16.1/URI.min.js"></script>
        
    
        
        <script src="../../../gitbook/gitbook-plugin-disqus/plugin.js"></script>
        
    
        
        <script src="../../../gitbook/gitbook-plugin-fontsettings/fontsettings.js"></script>
        
    

    </body>
</html>

